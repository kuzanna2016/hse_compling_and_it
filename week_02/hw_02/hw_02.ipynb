{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "домашнее задание о векторизации текстов.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPlA8mm5agWQ4XIne5tjyqH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/oserikov/f430e81939ffff48cafd6377b9e67b9c/.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh6wr5m8ZFot"
      },
      "source": [
        "# Домашнее задание о векторизации текстов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bm1AFbqZFIY"
      },
      "source": [
        "В задании вам предстоит сравнить несколько методов снижения размерности\n",
        "* PCA\n",
        "* t-SNE\n",
        "\n",
        "а так же попробовать осуществить тематическое моделирование методом LDA.\n",
        "\n",
        "**Формат сдачи задания** -- указание в гуглформе ссылки на тетрадь с решением + ответ на вопросы (см. последние вопросы первой задачи) в форме. Форма появится ближе к дедлайну.\n",
        "\n",
        "**Дедлайн** 23.59 7 октября MSK.  \n",
        "\n",
        "ДЗ предполагает возможность получения **до 12 баллов** по десятибалльной шкале. Оценки 11 и 12 поступают в ведомость, как оценки 11 и 12.\n",
        "\n",
        "---\n",
        "\n",
        "Если вы уже хорошо знакомы с снижением размерности, реализуйте первую задачу, используя не Bag-of-Words векторы текстов, а эмбеддинги текстов, полученные алгоритмом на ваш выбор. \n",
        "**Если вы собираетесь решать задачу так, то, приступая, сообщите об этом @oserikov в телеграме.**\n",
        "\n",
        "Если вы уже хорошо знакомы ещё и с векторизацией текстов эмбеддингами, напишите @oserikov для обсуждения замены первой задачи на другую.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHqgPgL_Z9XF"
      },
      "source": [
        "# [6 баллов] Задача о снижении размерности\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYhZCZwHnSan"
      },
      "source": [
        "[Вот](https://drive.google.com/drive/folders/1HX5rz4UZHtbzhPguUFolOg-xm6HFc0KO?usp=sharing) корпус, однажды собранный без особенных размышлений.\n",
        "Это -- корпус любительской литературы. Он был собран для забавы и непонятно, какая природа у представленных там текстов.\n",
        "\n",
        "Вам предстоит оценить, насколько эти тексты интересны в качестве простого датасета для задачи классификации: информативны ли Bag-of-Words векторы в смысле разделения текстов по жанрам.\n",
        "\n",
        "---\n",
        "\n",
        "### Постановка задачи\n",
        "\n",
        "**Задача**: взяв фанифики и два каких-то других жанра из корпуса, визуализировать их BoW-представления на плоскости.\n",
        "\n",
        "---\n",
        "\n",
        "Визуализацию стоит осуществлять scatter-плотом, информацию о принадлежности документа какому-то жанру стоит передавать цветом.\n",
        "\n",
        "Количество документов, представляющих каждый жанр, стоит подобрать семплированием нужного количества элементов под доступные вычислительные ресурсы -- полный корпус точно слишком велик.\n",
        "\n",
        "Гиперпараметры BoW-векторизатора стоит подобрать под доступные вычислительные ресурсы -- если код работает дольше часа, то стоит упростить вычислительную задачу: подобрать другие гиперпараметры векторизации или уменьшить выборку."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIbAkSSnnOp8"
      },
      "source": [
        "#### Критерии\n",
        "\n",
        "\n",
        "* **1 БАЛЛ**: \n",
        "  * В выбранных документах осуществлена какая-то **стандартная предобработка текста**: удалены стоп-слова и мусорные токены (e.g. html-теги), проведена лемматизация.  \n",
        "  Решение о каждой конкретной детали предобработки остаётся на усмотрение студентов: каждое нестандартное действие (e.g. отказ от лемматизации или удаление каких-то особенных токенов) стоит пояснить коротким комментарием, описывающим мотивацию.\n",
        "  * Получены **Bag-of-Words векторы** документов, выбранных для исследования. \n",
        "* **1 БАЛЛ**: получена визуализация документов на плоскости **методом главных компонент** снижения размерности Bag-of-Words векторов.\n",
        "* **1 БАЛЛ**: получена визуализация документов на плоскости методом **t-SNE** снижения размерности Bag-of-Words векторов.\n",
        "* **1 БАЛЛ**: на полученных визуализациях **получилось передать цветом точек классы** документов; понятно, точка какого цвета относится к какому классу.\n",
        "\n",
        "\n",
        "Скорее всего визуализация t-SNE и PCA заметно отличаются раскладкой точек по плоскости: один метод как будто раскладывает их вдоль двух пересекающихся прямых, за другим такого свойства скорее всего нет. Ответ на два вопроса ниже вам предстоит указать в гуглформе, сдавая задание.\n",
        "* **1 БАЛЛ**: верно указано, какой метод укладывает точки примерно вдоль прямых, а какой -- нет\n",
        "* **1 БАЛЛ**: предложено верное описание тому, почему у одного из методов всегда результаты располагаются вдоль некоторых прямых. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMEZ9Qng58B5"
      },
      "source": [
        "#### Примеры кода"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzf0J9IX6Kr6"
      },
      "source": [
        "Использование t-SNE и PCA для визуализации векторов: [ссылка](https://www.kaggle.com/jbencina/clustering-documents-with-tfidf-and-kmeans).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yv__Q1Wb1ny"
      },
      "source": [
        "## [6 баллов] Задача о тематическом моделировании\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-D75Q_5HF9"
      },
      "source": [
        "### об LDA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoZTPslmm0d9"
      },
      "source": [
        "\n",
        "\n",
        "### Постановка задачи\n",
        "Загрузите [коллекцию писем Х. Клинтон](https://www.kaggle.com/kaggle/hillary-clinton-emails/?select=Emails.csv) с kaggle. Для скачивания может потребоваться регистрация.\n",
        "\n",
        "Методом LDA выделите несколько тем в переписке Х. Клинтон, дайте им словесное описание. Используйте библиотеку LdaModel из gensim.\n",
        "\n",
        "#### Критерии\n",
        "\n",
        "* **2 БАЛЛА**: получены списки ключевых слов, не выглядящие бессмыслицей\n",
        "* **2 БАЛЛА**: осуществлена визуализация библиотекой pyLDAvis\n",
        "* **1 БАЛЛ**: предложено осмысленное текстовое описание большинства выделенных тем.\n",
        "* **1 БАЛЛ**: проведено сравнение LDA, запущенного на CountVectorizer и TfIdfVectorizer предтавлениях одних и тех же данных. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqnaLMAVm0Sb"
      },
      "source": [
        "#### примеры кода\n",
        "\n",
        "Пример обучения LdaModel на выдаче CountVectorizer: [ссылка](https://github.com/EricSchles/sklearn_gensim_example/blob/master/example.py)\n",
        "\n",
        "Пример использования pyLDAvis: секция 15 [по ссылке](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)\n",
        "\n",
        "---\n",
        "\n",
        "Для обучения *LdaModel* и её последующей визуализации потребуется словарь формата gensim. Словарь формата gensim удобно получать из сжатого csc_matrix-представления нашего векторизованного текста: как многие замечали на паре, tf-idf векторы содержат много нулей.\n",
        "\n",
        "```python\n",
        "import gensim\n",
        "from scipy.sparse import csc\n",
        "\n",
        "corpus = gensim.matutils.Sparse2Corpus(csc.csc_matrix(X))\n",
        "dictionary = gensim.corpora.Dictionary.from_corpus(corpus, vocab_dict)\n",
        "```\n",
        "\n",
        "где *corpora* содержит полученное с помощью gensim представление коллекции, а *vocab_dict* — это dict, полученный после работы Vectorizer, ставящий в соответствие каждому номеру строки в матрице данных само слово в виде строки."
      ]
    }
  ]
}