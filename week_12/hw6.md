Домашнее задание №6 (эмбеддинги + сети на keras)

В этом домашнем задании вы построите нейронную сеть на Keras для задачи классификации твитов. 
Посмотреть и скачать корпус можно из источника http://study.mokoron.com, (либо сразу по прямым ссылкам в ноутбуке

```
!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv
!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv 
```


Решите задачу, используя две следующие архитектуры, для каждой посчитайте accuracy, precision, recall *:

1. модель берет слова, пропускает их через Embedding слой. По эмбеддингам проходит biLSTM, на выходе линейный слой и выходной слой.

    - Embedding слой обучается внутри модели  -- 1 балл
    - подгружаются обученные эмбеддинги для русского языка **  -- 1 балл
    - fasttext эмбеддинги обучаются на всем корпусе с нуля *** -- 2 балла

2. усложним архитектуру. У этой модели два входа, один для эмбеддингов (выберете лучшие из предыдущего пункта), над ними  biLSTM по всему предложению. Другой вход сети для символьного представления слов ****. 
Каждое слово на втором входе пропускается через CharCNN. По полученным векторам на уровне предложения также проходит biLSTM. выходы обеих biLSTM  конкатенируются, далее линейный слой, далее выходной слой. --  3 балла

Еще про баллы:
 - Подготовка датасета, формирование матриц признаков --  1 балл
 - Внятное сравнение моделей между собой по качеству  -- 1 балл
 - Показано, что качество можно улучшить засчет работы с гиперпараметрами и/или доведения архитектуры (помогло изменение размера слоя/эмбеддингов, добавили Dropout и спаслись от переобучения, добавили слоев и т.д.) -- 1 балл



--------------------------------------


 __\*__ чтобы метрики считались во время обучения, при компиляции модели аргументом ``metrics`` передайте ей список 
 ```
 metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.Accuracy()]
 ```
 __**__ можете использовать gensim,  как в дз №4.
 Чтобы эмбеддинги использовались как веса Embedding  слоя, вам нужно сформировать матрицу весов weights, такую, что если  ``id2word['слон'] == 123``, то ``weights[123] == <эмбеддинг слова "слон">``. 

Подгружается в сеть она так:
```
 tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=output_dim, trainable=False, weights=[weights])
```
 __***__ с помощью gensim обучение запускается так:
```
 ft = gensim.models.FastText(texts, size=size, iter=iter)
```
___\****__  идея с двумя входами показана в материале 12 недели.

--------------

***Дедлайн*** - 7 февраля 23:59
